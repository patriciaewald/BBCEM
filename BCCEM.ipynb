{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "qtrvDuTHEokk",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# *Architecture independent generalization bounds for overparametrized deep ReLU networks*\n",
    "\n",
    "Code used to generate data for [*Architecture independent generalization bounds for overparametrized deep ReLU networks*](https://arxiv.org/abs/2504.05695), by Anandatheertha Bapu, Thomas Chen, Chun-Kai Kevin Chien, Patrícia Muñoz Ewald, and Andrew G. Moore. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8PGAswHW5wZ2"
   },
   "source": [
    "## Imports and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "EZAYRBxN6uLI",
    "outputId": "7820f81b-4d25-4751-d659-72a93355c56f",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mnist = datasets.MNIST(root=\".\", train=True, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MxZr7i5V6yT9",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def train_imports(n, seed):\n",
    "    torch.manual_seed(seed)\n",
    "    training_indices = torch.randint(0,60000, (n,))\n",
    "    train_samples = [mnist[i] for i in training_indices]\n",
    "    X0_train = torch.stack([s[0].view(-1) for s in train_samples], dim=1)  \n",
    "    labels_train = torch.tensor([s[1] for s in train_samples]).T\n",
    "    Y_train = torch.eye(10)[labels_train].T \n",
    "    \n",
    "    return X0_train, Y_train, labels_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O3Hfym8y62Yp",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def test_imports(m, seed):\n",
    "    torch.manual_seed(seed)\n",
    "    test_indices = torch.randint(0,60000, (m,))\n",
    "    test_samples = [mnist[i] for i in test_indices]\n",
    "    X0_test = torch.stack([s[0].view(-1) for s in test_samples], dim=1)\n",
    "    labels_test = torch.tensor([s[1] for s in test_samples]).T\n",
    "    Y_test = torch.eye(10)[labels_test].T\n",
    "    \n",
    "    return X0_test, Y_test, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uER4A8umBpV6",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def has_all_mnist_digits(labels):\n",
    "    labels = np.array(labels)\n",
    "    unique_digits = np.unique(labels)\n",
    "    all_digits = set(range(10))\n",
    "    missing_digits = sorted(all_digits - set(unique_digits))\n",
    "    \n",
    "    return len(missing_digits) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "3dPIFRNQ-1D3",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Chamfer Distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _to_numpy(x):\n",
    "    # Accepts either np.array or torch.Tensor, returns np.array on CPU\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return x.detach().cpu().numpy()\n",
    "    return np.asarray(x, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def chamfer_distance_labeled(X1, Y1, X2, Y2): \n",
    "    \"\"\"\n",
    "    Asymmetric Chamfer distance from (X1, Y1) to (X2, Y2) using\n",
    "        d((x1,y1),(x2,y2)) = (||x1 - x2||_2 + ||y1 - y2||_2)^2.\n",
    "    \n",
    "    This version is meant for metrics/logging:\n",
    "    - If inputs are torch.Tensors, they are detached and moved to CPU.\n",
    "    - No gradients will flow through this function.\n",
    "    \"\"\"\n",
    "   \n",
    "    X1 = _to_numpy(X1)\n",
    "    Y1 = _to_numpy(Y1)\n",
    "    X2 = _to_numpy(X2)\n",
    "    Y2 = _to_numpy(Y2)\n",
    "   \n",
    "    assert X2.shape[0] == Y2.shape[0], \"X2 and Y2 must have same number of points\"\n",
    "    assert X1.shape[1] == X2.shape[1], \"X1 and X2 must have same feature dimension\"\n",
    "    assert Y1.shape[1] == Y2.shape[1], \"Y1 and Y2 must have same label dimension\"\n",
    "\n",
    "    # Pairwise distances in feature space\n",
    "    diff_x = X1[:, None, :] - X2[None, :, :]   # (N1, N2, d)\n",
    "    dx = np.linalg.norm(diff_x, axis=-1)       # (N1, N2)\n",
    "\n",
    "    # Pairwise distances in label space\n",
    "    diff_y = Y1[:, None, :] - Y2[None, :, :]   # (N1, N2, Q)\n",
    "    dy = np.linalg.norm(diff_y, axis=-1)       # (N1, N2)\n",
    "\n",
    "    # Total pairwise distances\n",
    "    d = (dx + dy) ** 2                         \n",
    "\n",
    "    # For each point in cloud 1, find nearest neighbor in cloud 2\n",
    "    min_d = d.min(axis=1)\n",
    "\n",
    "    # Asymmetric Chamfer: average nearest-neighbor distance\n",
    "    cd = min_d.mean()\n",
    "\n",
    "    return cd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1WYy7oHs8ULe",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class ReLUNetwork(nn.Module):\n",
    "    def __init__(self, layers, bias = False):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(len(layers)-1):\n",
    "            self.layers.append(nn.Linear(layers[i], layers[i+1], bias=bias))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.layers)):\n",
    "            x = self.layers[i](x)\n",
    "            if i < len(self.layers) - 1:\n",
    "                x = F.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-tEXc0Jf_-NF",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def trained_model_error(X, Y, model):\n",
    "    sum = 0\n",
    "    for i in range(len(X.T)):\n",
    "        error = model(X.T[i]) - Y.T[i]\n",
    "    \n",
    "    for j in error:\n",
    "        sum += j**2\n",
    "    \n",
    "    return sum/len(X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oXVPcGjV7Aom",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class zeroLossNetwork():\n",
    "    def __init__(self, M, X0, Y):\n",
    "        M0 = X0.size(0)\n",
    "        Q, n = Y.size()\n",
    "        self.L = len(M)\n",
    "        \n",
    "        \n",
    "        # Exception handling\n",
    "        if M0 < n:\n",
    "            raise Exception('M0 must be >= n')\n",
    "        \n",
    "        if M[self.L-1] < Q:\n",
    "            raise Exception('All elements of M must be >= Q')\n",
    "        \n",
    "        for i in range(self.L-1):\n",
    "            if M[i] < M[i+1]:\n",
    "                raise Exception('M must be nonincreasing')\n",
    "        \n",
    "        # alpha and output bias\n",
    "        alpha = (-1*Y).max() # = 0 in this case for unit vectors in Y\n",
    "        \n",
    "        # First layer W1^*\n",
    "        X0T = X0.T\n",
    "        X0_plus = torch.linalg.pinv(X0)   # M0 x n pseudoinverse\n",
    "        top = (Y) @ X0_plus       # Q x M0\n",
    "        bottom = torch.zeros(M[0] - Q, M0)\n",
    "        self.W1 = torch.cat([top, bottom], dim=0)\n",
    "        \n",
    "        \n",
    "        # Hidden layer weights W_l^*, l=2,...,L. W_hidden[i](below) <-> W_(i+2)^*(in the paper)\n",
    "        self.W_hidden = []\n",
    "        for l in range(1, self.L):  # l=1,...,L\n",
    "            left = torch.eye(M[l])\n",
    "            right = torch.zeros(M[l], M[l-1] - M[l])\n",
    "            self.W_hidden.append(torch.cat([left, right], dim=1))\n",
    "            \n",
    "        \n",
    "        # Output weight W_(L+1)^*\n",
    "        self.WLp1 = torch.cat([torch.eye(Q), torch.zeros(Q, M[self.L-1] - Q)], dim=1)  \n",
    "\n",
    "\n",
    "  # Forward method\n",
    "    def forward(self, X0):\n",
    "        x = F.relu(self.W1 @ X0)\n",
    "        for l in range(self.L-1):\n",
    "            x = self.W_hidden[l] @ x\n",
    "            x = F.relu(x) # Apply ReLU activation\n",
    "        out = self.WLp1 @ x\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4rh7dNNM-txt",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def initializedNetworkError(X, Y, model):\n",
    "    sum = 0\n",
    "    for i in range(len(X.T)):\n",
    "        error = model.forward(X.T[i]) - Y.T[i]\n",
    "    for j in torch.squeeze(error):\n",
    "        sum += j**2\n",
    "    return sum/len(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "ocdwWTAM_SYD",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "###  Basic code for experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`zeroLossNetworkExperiment` initializes a zeroLossNetwork() interpolating `n` MNIST samples using a specific `train_seed`. It then generates a test set with `m` elements from seed `test_seed`, and outputs the following:\n",
    "- Train error\n",
    "- Test error\n",
    "- Certain bounds\n",
    "- $||W_1 - W_1 X_0 (X_0)^+||$\n",
    "- Operator norms of the weight matrices\n",
    "- `train_seed, test_seed`\n",
    "\n",
    "`trainedNetwork` initializes a ReLUNetwork() with layer dimensions given by an array `M`, possibly with bias (if `bias=True`), either randomly (if `from_random=True`) or using the parameters from a zeroLossNetwork() (if `from_random=False`), and then trains it to interpolate `n` MNIST samples generatem from seed `train_seed`. The training parameters are:\n",
    "- `l` learning rate, or `lr_from_constructors` if `from_random=False`,\n",
    "- `wd` weight decay,\n",
    "- `batch_size`,\n",
    "- `epochs`,\n",
    "- `init_seed` seed for random initialization\n",
    "Returns: model, seed, seed\n",
    "\n",
    "`trainedNetworkExperiment` then takes a `model` trained with `train_seed, init_seed, n, M` as above, generates a test set with `m` elements from seed `test_seed`, and outputs the following:\n",
    "- Train error\n",
    "- Test error\n",
    "- Certain bounds\n",
    "- $||W_1 - W_1 X_0 (X_0)^+||$\n",
    "- Operator norms of the weight matrices\n",
    "- `train_seed, test_seed, init_seed`\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "4mLs3Al2909B"
   },
   "source": [
    "___\n",
    "**List of parameters**\n",
    "\n",
    "Required Parameters \n",
    "* `n` = int, training set size\n",
    "* `m` = int, test set size\n",
    "* `M` = list, architecture of network. Enter all numbers from M0 to Q (inclusive) as a list.\n",
    "\n",
    "Optional parameters:\n",
    "\n",
    "* `train_seed` seed for generating training set, `default=30`\n",
    "* `test_seed` seed for generating test set, `default=10`\n",
    "* `l` = float, learning rate, `default=0.1`\n",
    "* `wd` = float, weight decay, `default=0.0`\n",
    "* `from_random` = boolean, True if training from random, False if prefilled with zero loss minimizers, `default=True`\n",
    "* `batch_size` = int, `default=1`\n",
    "* `epochs` = int, `default=100`\n",
    "* `lr_from_constructors` = float, learning rate if prefilled with zero loss minimizers, `default=0.1`\n",
    "* `bias` = boolean, `default=False`\n",
    "* `print_loss` = boolean, prints loss every 10 epochs if True, `default=False`\n",
    "\n",
    "Note: If the training set does not contain a digit, the program throws it out and iterates through seeds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kZZK4j0R-vrm",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def zeroLossNetworkExperiment(n, m, M, train_seed = 30, test_seed = 10):\n",
    "    \n",
    "    has_all_digits = False\n",
    "    while not has_all_digits:\n",
    "        X0, Y0, L0 = train_imports(n, train_seed)\n",
    "        X, Y, L = test_imports(m, test_seed)\n",
    "        train_seed +=1\n",
    "        has_all_digits = has_all_mnist_digits(L0)\n",
    "    \n",
    "    model = zeroLossNetwork(M, X0, Y0)\n",
    "    train_out = model.forward(X0)\n",
    "    test_out = model.forward(X)\n",
    "    train_error = initializedNetworkError(X0, Y0, model)\n",
    "    test_error = initializedNetworkError(X, Y, model)\n",
    "    \n",
    "    W1 = model.W1\n",
    "\n",
    "    op_norms = []\n",
    "    op_norms.append(torch.linalg.norm(model.W1, ord=2).item())\n",
    "    for i in range(len(model.W_hidden)):\n",
    "        op_norms.append(torch.linalg.norm(model.W_hidden[i], ord=2).item())\n",
    "    op_norms.append(torch.linalg.norm(model.WLp1, ord=2).item())\n",
    "\n",
    "    prod_norms = math.prod(op_norms)\n",
    "    \n",
    "    # Computes the product of weight matrices \n",
    "    prod_weights = model.W1            # For all matrices\n",
    "    prod_weights_g = torch.eye(M[0])   # Excluding W1\n",
    "    for i in range(len(model.W_hidden)):\n",
    "        prod_weights = model.W_hidden[i] @ prod_weights\n",
    "        prod_weights_g = model.W_hidden[i] @ prod_weights_g\n",
    "    prod_weights = model.WLp1 @ prod_weights\n",
    "    prod_weights_g = model.WLp1 @ prod_weights_g\n",
    "\n",
    "    # Lipf = torch.linalg.norm(prod_weights, ord = 2)\n",
    "    Lipf = prod_norms\n",
    "    Lipg = torch.linalg.norm(prod_weights_g, ord = 2)\n",
    "    \n",
    "    bound0 = (max(1, Lipf))**2 * chamfer_distance_labeled(X.T, Y.T, X0.T, Y0.T)\n",
    "    bound1 = (max(1, Lipg))**2 * chamfer_distance_labeled((W1 @ X).T, Y.T, (W1 @ X0).T, Y0.T)\n",
    "    bound2 = (max(1, Lipg))**2 * chamfer_distance_labeled(F.relu((W1 @ X).T), Y.T, F.relu((W1 @ X0).T), Y0.T)\n",
    "    \n",
    "    dist = torch.linalg.norm(W1 - (W1 @ X0 @ torch.linalg.pinv(X0)))\n",
    "    \n",
    "    return (\n",
    "      np.array(train_error), \n",
    "      np.array(test_error), \n",
    "      np.array(bound0), \n",
    "      np.array(bound1), \n",
    "      np.array(bound2),\n",
    "      np.array(dist), \n",
    "      np.array(op_norms), \n",
    "      np.array(train_seed)-1, # Because check for all numbers does always does an extra +1 \n",
    "      np.array(test_seed), \n",
    "      None\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OX7yy6z_J48M",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def trainedNetwork(n, M, bias = False, from_random=True,\n",
    "                   l=0.1, lr_from_contructors = 0.1, wd=0.0,  batch_size=1, epochs=100, print_loss=False, \n",
    "                   train_seed = 30, init_seed=None):\n",
    "    '''\n",
    "    Returns\n",
    "    Trained ReLUNetwork(), train_seed used, seed used for parameter initialization\n",
    "    '''\n",
    "    \n",
    "    has_all_digits = False\n",
    "    while not has_all_digits:\n",
    "        X0, Y0, L0 = train_imports(n, train_seed)\n",
    "        train_seed +=1\n",
    "        has_all_digits = has_all_mnist_digits(L0)\n",
    "    \n",
    "    if init_seed == None:\n",
    "        torch.seed()\n",
    "    else:\n",
    "        torch.manual_seed(init_seed)\n",
    "    model0 = ReLUNetwork(M, bias)\n",
    "    seed = torch.random.initial_seed()\n",
    "    #print(f\"The seed used is: {seed}\")\n",
    "    \n",
    "    \n",
    "    if not from_random:\n",
    "        model = zeroLossNetwork(M[1:len(M)-1], X0, Y0)\n",
    "        with torch.no_grad():\n",
    "            model0.layers[0].weight.copy_(model.W1)\n",
    "            i = 1\n",
    "            for w in model.W_hidden:\n",
    "                model0.layers[i].weight.copy_(w)\n",
    "                i += 1\n",
    "                model0.layers[i].weight.copy_(model.WLp1)\n",
    "        l = lr_from_contructors\n",
    "    \n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(model0.parameters(), lr = l, weight_decay = wd)\n",
    "    \n",
    "    dataset = torch.utils.data.TensorDataset(X0.T, Y0.T)\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        for xb, yb in loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model0(xb)\n",
    "            loss = loss_fn(output, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if print_loss and e%10==0:\n",
    "            print(loss_fn(model0(X0.T), Y0.T)*10)\n",
    "    \n",
    "    return model0, train_seed-1, seed # Because check for all numbers does always does an extra +1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OX7yy6z_J48M",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def trainedNetworkExperiment(model, train_seed, init_seed, \n",
    "                             n, m, M, \n",
    "                             test_seed = 10):\n",
    "    X, Y, L = test_imports(m, test_seed)\n",
    "    X0, Y0, L0 = train_imports(n, train_seed)\n",
    "    \n",
    "    model0 = model\n",
    "    train_error = trained_model_error(X0, Y0, model0)\n",
    "    test_error = trained_model_error(X, Y, model0)\n",
    "    \n",
    "    W1 = model0.layers[0].weight\n",
    "    \n",
    "    # Computes the product of the operator norms of the weight matrices\n",
    "    op_norms = []\n",
    "    for i in range(len(model0.layers)):\n",
    "        op_norms.append(torch.linalg.norm(model0.layers[i].weight, ord=2).item())\n",
    "    prod_norms = math.prod(op_norms)\n",
    "    \n",
    "    # Computes the product of weight matrices\n",
    "    prod_weights = torch.eye(M[0])\n",
    "    for i in range(len(model0.layers)):\n",
    "        prod_weights = model0.layers[i].weight @ prod_weights\n",
    "    \n",
    "    # Computes the product of weight matrices, excluding W1\n",
    "    prod_weights_g = torch.eye(M[1])\n",
    "    for i in range(1, len(model0.layers)):\n",
    "        prod_weights_g = model0.layers[i].weight @ prod_weights_g\n",
    "    \n",
    "    \n",
    "    # Lipf = torch.linalg.norm(prod_weights, ord = 2)\n",
    "    Lipf = prod_norms\n",
    "    Lipg = torch.linalg.norm(prod_weights_g, ord = 2)\n",
    "    \n",
    "    bound0 = (max(1, Lipf))**2 * chamfer_distance_labeled(X.T, Y.T, X0.T, Y0.T)\n",
    "    bound1 = (max(1, Lipg))**2 * chamfer_distance_labeled((W1 @ X).T, Y.T, (W1 @ X0).T, Y0.T)\n",
    "    bound2 = (max(1, Lipg))**2 * chamfer_distance_labeled(F.relu((W1 @ X).T), Y.T, F.relu((W1 @ X0).T), Y0.T)\n",
    "    \n",
    "    dist = torch.linalg.norm(W1 - (W1 @ X0 @ torch.linalg.pinv(X0)))\n",
    "\n",
    "    return (\n",
    "      _to_numpy(train_error), \n",
    "      _to_numpy(test_error), \n",
    "      _to_numpy(bound0), \n",
    "      _to_numpy(bound1), \n",
    "      _to_numpy(bound2),\n",
    "      _to_numpy(dist), \n",
    "      _to_numpy(op_norms), \n",
    "      _to_numpy(train_seed),   \n",
    "      _to_numpy(test_seed), \n",
    "      _to_numpy(init_seed)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Generating data frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Shorthands:\n",
    "* ZL   = zeroLossNetworkExperiment\n",
    "* RI   = trainedNetworkExperiment with from_random=True\n",
    "* TFZL = trainedNetworkExperiment with from_random=False\n",
    "\n",
    "The function `train_and_run_all_experiments` runs experiments and returns a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_run_all_experiments(n_list, M,\n",
    "                        num_RI_runs=10,\n",
    "                        tol=1e-3,\n",
    "                        TFZL=False, random_init=False,\n",
    "                        train_seed=30, test_seed=10,\n",
    "                        epochs = 100,\n",
    "                        scenarios=[\"fixed_m\", \"m_eq_n\"],\n",
    "                        save_models=True):\n",
    "    \"\"\"\n",
    "    Run RI, ZL, TFZL for:\n",
    "      - scenario 'fixed_m': m = min(n_list)\n",
    "      - scenario 'm_eq_n':  m = n\n",
    "\n",
    "    Returns\n",
    "    df : pandas.DataFrame\n",
    "        One row per run, including all outputs and parameters.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    m_fixed = min(n_list)\n",
    "\n",
    "    # To keep track of network training progress\n",
    "    nets_to_train = len(scenarios)*len(n_list)*(num_RI_runs*int(random_init) + int(TFZL))\n",
    "    trained = 0\n",
    "\n",
    "    for scenario in scenarios:\n",
    "        for n in n_list:\n",
    "            if scenario == \"fixed_m\":\n",
    "                m = m_fixed\n",
    "            else:\n",
    "                m = n\n",
    "\n",
    "            # ZL: zeroLossNetworkExperiment (single run per (n,m))\n",
    "            Etrain, Etest, b0, b1, b2, dist, op_norms, train_seed, test_seed, seed = zeroLossNetworkExperiment(\n",
    "                n, m, M, train_seed=train_seed, test_seed=test_seed\n",
    "            )\n",
    "            results.append(\n",
    "                dict(\n",
    "                    scenario=scenario,\n",
    "                    exp_type=\"ZL\",\n",
    "                    n=n,\n",
    "                    m=m,\n",
    "                    M=M,\n",
    "                    run_idx=0,\n",
    "                    train_seed=train_seed,\n",
    "                    test_seed=test_seed,\n",
    "                    init_seed=seed,\n",
    "                    Etrain=float(Etrain),\n",
    "                    Etest=float(Etest),\n",
    "                    b0=float(b0),\n",
    "                    b1=float(b1),\n",
    "                    b2=float(b2),\n",
    "                    dist=dist,\n",
    "                    op_norm_W1=op_norms[0],\n",
    "                    op_norms=op_norms,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            if TFZL==True:\n",
    "                # TFZL: trainedNetwork with from_random=False (single run per (n, m))\n",
    "                model, train_seed, init_seed = trainedNetwork(n, M, epochs=epochs, from_random=False, train_seed=train_seed)\n",
    "                Etrain, Etest, b0, b1, b2, dist, op_norms, train_seed, test_seed, seed = trainedNetworkExperiment(\n",
    "                    model, train_seed, init_seed,\n",
    "                    n, m, M,  test_seed\n",
    "                )\n",
    "                results.append(\n",
    "                    dict(\n",
    "                        scenario=scenario,\n",
    "                        exp_type=\"TFZL\",\n",
    "                        n=n,\n",
    "                        m=m,\n",
    "                        M=M,\n",
    "                        run_idx=0,\n",
    "                        train_seed=train_seed,\n",
    "                        test_seed=test_seed,\n",
    "                        init_seed=seed,\n",
    "                        Etrain=float(Etrain),\n",
    "                        Etest=float(Etest),\n",
    "                        b0=float(b0),\n",
    "                        b1=float(b1),\n",
    "                        b2=float(b2),\n",
    "                        dist=dist,\n",
    "                        op_norm_W1=op_norms[0],\n",
    "                        op_norms=op_norms\n",
    "                    )\n",
    "                )\n",
    "                trained += 1\n",
    "                print(f\"{trained} out of {nets_to_train} networks trained; {datetime.now()}\")\n",
    "                if save_models==True:\n",
    "                    torch.save(model.state_dict(), f\"params_TFZL_{M}_{n}.pt\")\n",
    "\n",
    "            if random_init==True:\n",
    "                # RI: trainedNetwork with from_random=True, multiple seeds\n",
    "                for run_idx in range(num_RI_runs):\n",
    "                    model, train_seed, init_seed = trainedNetwork(n, M, epochs=epochs, from_random=True, train_seed=train_seed)\n",
    "                    Etrain, Etest, b0, b1, b2, dist, op_norms, train_seed, test_seed, seed = trainedNetworkExperiment(\n",
    "                        model, train_seed, init_seed,\n",
    "                        n, m, M,  test_seed\n",
    "                    )\n",
    "                    results.append(\n",
    "                        dict(\n",
    "                            scenario=scenario,\n",
    "                            exp_type=\"RI\",\n",
    "                            n=n,\n",
    "                            m=m,\n",
    "                            M=M,\n",
    "                            run_idx=run_idx,\n",
    "                            train_seed=train_seed,\n",
    "                            test_seed=test_seed,\n",
    "                            init_seed=seed,\n",
    "                            Etrain=float(Etrain),\n",
    "                            Etest=float(Etest),\n",
    "                            b0=float(b0),\n",
    "                            b1=float(b1),\n",
    "                            b2=float(b2),\n",
    "                            dist=dist,\n",
    "                            op_norm_W1=op_norms[0],\n",
    "                            op_norms=op_norms,\n",
    "                        )\n",
    "                    )\n",
    "                    trained += 1\n",
    "                    print(f\"{trained} out of {nets_to_train} networks trained; {datetime.now()}\")\n",
    "                    if save_models==True:\n",
    "                        torch.save(model.state_dict(), f\"params_RI-{run_idx}_{M}_{n}.pt\")\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def train_nets(n_list, M, train_seed=30, \n",
    "               TFZL=False, \n",
    "               random_init=False, num_RI_runs=10,\n",
    "               epochs = 100):\n",
    "    \n",
    "    nets_to_train = len(n_list)*(num_RI_runs*int(random_init) + int(TFZL))\n",
    "    trained = 0\n",
    "    \n",
    "    for n in n_list:\n",
    "        if TFZL:\n",
    "            model, _, _ = trainedNetwork(n, M, from_random=False, train_seed=train_seed, epochs=epochs)\n",
    "            os.makedirs(\"models\", exist_ok=True)\n",
    "            torch.save(model.state_dict(), f\"models/params_TFZL_{M}_n{n}_e{epochs}.pt\")\n",
    "            \n",
    "            trained += 1\n",
    "            print(f\"{trained} out of {nets_to_train} networks trained; {datetime.now()}\")\n",
    "\n",
    "        if random_init:\n",
    "            for run_idx in range(num_RI_runs):\n",
    "                model, _, seed = trainedNetwork(n, M, from_random=True, train_seed=train_seed, epochs=epochs)\n",
    "                os.makedirs(f\"models/{M}/{n}\", exist_ok=True)\n",
    "                torch.save(model.state_dict(), f\"models/{M}/{n}/params_RI_{M}_n{n}_e{epochs}_s{seed}.pt\")\n",
    "                \n",
    "                trained += 1\n",
    "                print(f\"{trained} out of {nets_to_train} networks trained; {datetime.now()}\")\n",
    "                #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def networks_to_df(n_list,\n",
    "                        M, bias=False,\n",
    "                        num_RI_runs=10,\n",
    "                        TFZL=True, random_init=True,\n",
    "                        train_seed=30, test_seed=10,\n",
    "                        epochs = 100,\n",
    "                        scenarios=[\"fixed_m\", \"m_eq_n\"]):\n",
    "    \"\"\"\n",
    "    Run RI, ZL, TFZL for:\n",
    "      - scenario 'fixed_m': m = min(n_list)\n",
    "      - scenario 'm_eq_n':  m = n\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas.DataFrame\n",
    "        One row per run, including all outputs and parameters.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    m_fixed = min(n_list)\n",
    "\n",
    "    for scenario in scenarios:\n",
    "        for n in n_list:\n",
    "            if scenario == \"fixed_m\":\n",
    "                m = m_fixed\n",
    "            else:\n",
    "                m = n\n",
    "\n",
    "            # ZL: zeroLossNetworkExperiment (single run per (n,m))\n",
    "            Etrain, Etest, b0, b1, b2, dist, op_norms, train_seed, test_seed, seed = zeroLossNetworkExperiment(\n",
    "                n, m, M, train_seed=train_seed, test_seed=test_seed\n",
    "            )\n",
    "            results.append(\n",
    "                dict(\n",
    "                    scenario=scenario,\n",
    "                    exp_type=\"ZL\",\n",
    "                    n=n,\n",
    "                    m=m,\n",
    "                    M=M,\n",
    "                    run_idx=0,\n",
    "                    train_seed=train_seed,\n",
    "                    test_seed=test_seed,\n",
    "                    init_seed=seed,\n",
    "                    Etrain=float(Etrain),\n",
    "                    Etest=float(Etest),\n",
    "                    b0=float(b0),\n",
    "                    b1=float(b1),\n",
    "                    b2=float(b2),\n",
    "                    dist=dist,\n",
    "                    op_norm_W1=op_norms[0],\n",
    "                    op_norms=op_norms,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            if TFZL==True:\n",
    "                # TFZL: trainedNetworkExperiment with from_random=False (single run)\n",
    "                model = ReLUNetwork(M, bias)\n",
    "                model.load_state_dict(torch.load(f\"models/{M}_trainseed{int(train_seed)}/TFZL/params_TFZL_{M}_n{n}_e{epochs}.pt\", weights_only=True))\n",
    "                Etrain, Etest, b0, b1, b2, dist, op_norms, train_seed, test_seed, seed = trainedNetworkExperiment(\n",
    "                    model, train_seed, None, n, m, M, test_seed\n",
    "                )\n",
    "                results.append(\n",
    "                    dict(\n",
    "                        scenario=scenario,\n",
    "                        exp_type=\"TFZL\",\n",
    "                        n=n,\n",
    "                        m=m,\n",
    "                        M=M,\n",
    "                        run_idx=0,\n",
    "                        train_seed=train_seed,\n",
    "                        test_seed=test_seed,\n",
    "                        init_seed=seed,\n",
    "                        Etrain=float(Etrain),\n",
    "                        Etest=float(Etest),\n",
    "                        b0=float(b0),\n",
    "                        b1=float(b1),\n",
    "                        b2=float(b2),\n",
    "                        dist=dist,\n",
    "                        op_norm_W1=op_norms[0],\n",
    "                        op_norms=op_norms\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            if random_init==True:\n",
    "                # RI: trainedNetworkExperiment with from_random=True, multiple seeds\n",
    "                directory_path = f\"models/{M}_trainseed{int(train_seed)}/{n}\"\n",
    "                run_idx = 0\n",
    "                for file in os.listdir(directory_path):\n",
    "                    full_path = os.path.join(directory_path, file)\n",
    "                    model = ReLUNetwork(M, bias)\n",
    "                    model.load_state_dict(torch.load(full_path, weights_only=True))\n",
    "                    seed = re.search(r\"_s(\\d+)\\.pt$\", file)\n",
    "                    if not m:\n",
    "                        raise ValueError(f\"No '_s<digits>.pt' seed found in: {file}\")\n",
    "                    \n",
    "                    Etrain, Etest, b0, b1, b2, dist, op_norms, train_seed, test_seed, seed = trainedNetworkExperiment(\n",
    "                        model, train_seed, None, n, m, M, test_seed\n",
    "                    )\n",
    "                    results.append(\n",
    "                        dict(\n",
    "                            scenario=scenario,\n",
    "                            exp_type=\"RI\",\n",
    "                            n=n,\n",
    "                            m=m,\n",
    "                            M=M,\n",
    "                            run_idx=run_idx,\n",
    "                            train_seed=train_seed,\n",
    "                            test_seed=test_seed,\n",
    "                            init_seed=seed,\n",
    "                            Etrain=float(Etrain),\n",
    "                            Etest=float(Etest),\n",
    "                            b0=float(b0),\n",
    "                            b1=float(b1),\n",
    "                            b2=float(b2),\n",
    "                            dist=dist,\n",
    "                            op_norm_W1=op_norms[0],\n",
    "                            op_norms=op_norms,\n",
    "                        )\n",
    "                    )\n",
    "                    run_idx += 1\n",
    "                    if run_idx == num_RI_runs: break\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _aggregate_by_n(df, n_list, cols):\n",
    "    \"\"\"\n",
    "    Helper: for a DataFrame already filtered by scenario and exp_type,\n",
    "    return ns (subset of n_list that exists in df) and mean/std for given cols.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return [], {c: np.array([]) for c in cols}, {c: np.array([]) for c in cols}\n",
    "\n",
    "    g = df.groupby(\"n\")\n",
    "    ns = [n for n in n_list if n in g.indices]\n",
    "\n",
    "    means = {}\n",
    "    stds = {}\n",
    "    for col in cols:\n",
    "        means[col] = np.array([g.get_group(n)[col].mean() for n in ns])\n",
    "        stds[col]  = np.array([g.get_group(n)[col].std(ddof=0) for n in ns])\n",
    "    return ns, means, stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 12})  # Sets font size for all plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produces 3 plots of test error and bound(s) computed, one for each of (ZL, TFZL, RI):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_Etest_and_bounds(df, n_list, tol=1e-3, scenario=\"fixed_m\", save=False):\n",
    "    \"\"\"\n",
    "    1) Single plot of Etest and bound(s) vs n for RI (good seeds: Etrain < tol)\n",
    "    2) Single plot of Etest and bound(s) vs n for ZL\n",
    "    3) Single plot of Etest and bound(s) vs n for TFZL\n",
    "\n",
    "    scenario: 'fixed_m' or 'm_eq_n' (default 'fixed_m')\n",
    "    \"\"\"\n",
    "    cols = [\"Etrain\", \"Etest\", \"b1\"]\n",
    "\n",
    "    # ----- RI (good seeds) -----\n",
    "    df_RI = df[(df[\"scenario\"] == scenario) &\n",
    "               (df[\"exp_type\"] == \"RI\") &\n",
    "               (df[\"Etrain\"] < tol)]\n",
    "    ns_RI, means_RI, stds_RI = _aggregate_by_n(df_RI, n_list, cols)\n",
    "\n",
    "    if ns_RI:\n",
    "        fig, ax = plt.subplots(figsize=(7, 5))\n",
    "        ax.errorbar(ns_RI, means_RI[\"Etest\"], yerr=stds_RI[\"Etest\"],\n",
    "                    fmt=\"o-\", label=r\"$\\mathcal{E}^{test}$\", capsize=3)\n",
    "        # ax.errorbar(ns_RI, means_RI[\"b2\"],   yerr=stds_RI[\"b2\"],\n",
    "        #             fmt=\"x--\", label=\"Bound 2\", capsize=3)\n",
    "        ax.errorbar(ns_RI, means_RI[\"b1\"],   yerr=stds_RI[\"b1\"],\n",
    "                    fmt=\"d-\", label=\"Bound\", capsize=3)\n",
    "        ax.set_xlabel(\"n\")\n",
    "        # ax.set_ylabel(\"Value\")\n",
    "        if scenario==\"fixed_m\":\n",
    "            ax.set_title(f\"Random initialization ($\\mathcal{{E}}^{{train}} \\leq {tol}$, m={min(n_list)})\")\n",
    "        if scenario==\"m_eq_n\":\n",
    "            ax.set_title(f\"Random initialization ($\\mathcal{{E}}^{{train}} \\leq {tol}$, m=n)\")\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save==True:\n",
    "            os.makedirs(\"plots\", exist_ok=True)\n",
    "            fname = f\"plots/Etest_b1_b2_RI_tol{tol:g}_{scenario}.png\"\n",
    "            fig.savefig(fname, dpi=200)\n",
    "\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"No RI runs with Etrain < {tol} for scenario '{scenario}'.\")\n",
    "\n",
    "    # ----- ZL -----\n",
    "    df_ZL = df[(df[\"scenario\"] == scenario) &\n",
    "               (df[\"exp_type\"] == \"ZL\")]\n",
    "    ns_ZL, means_ZL, stds_ZL = _aggregate_by_n(df_ZL, n_list, cols)\n",
    "\n",
    "    if ns_ZL:\n",
    "        fig, ax = plt.subplots(figsize=(7, 5))\n",
    "        ax.plot(ns_ZL, means_ZL[\"Etest\"], \n",
    "                    \"o-\", label=r\"$\\mathcal{E}^{test}$\")\n",
    "        # ax.plot(ns_ZL, means_ZL[\"Etrain\"],  ## Remove\n",
    "        #             \"s-\", label=r\"$\\mathcal{E}^{train}$\")\n",
    "        # ax.plot(ns_ZL, means_ZL[\"b2\"],   \n",
    "        #             \"x--\", label=\"b2\")\n",
    "        ax.plot(ns_ZL, means_ZL[\"b1\"],   \n",
    "                    \"d-\", label=\"Bound\")\n",
    "        ax.set_xlabel(\"n\")\n",
    "        # ax.set_ylabel(\"Value\")\n",
    "        if scenario==\"fixed_m\":\n",
    "            ax.set_title(f\"Zero loss network (m={min(n_list)})\")\n",
    "        if scenario==\"m_eq_n\":\n",
    "            ax.set_title(f\"Zero loss network (m=n)\")\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save==True:\n",
    "            os.makedirs(\"plots\", exist_ok=True)\n",
    "            fname = f\"plots/Etest_b1_b2_ZL_{scenario}.png\"\n",
    "            fig.savefig(fname, dpi=200)\n",
    "\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"No ZL runs for scenario '{scenario}'.\")\n",
    "\n",
    "    # ----- TFZL -----\n",
    "    df_TFZL = df[(df[\"scenario\"] == scenario) &\n",
    "                 (df[\"exp_type\"] == \"TFZL\")]\n",
    "    ns_TFZL, means_TFZL, stds_TFZL = _aggregate_by_n(df_TFZL, n_list, cols)\n",
    "\n",
    "    if ns_TFZL:\n",
    "        fig, ax = plt.subplots(figsize=(7, 5))\n",
    "        ax.plot(ns_TFZL, means_TFZL[\"Etest\"], \n",
    "                    \"o-\", label=r\"$\\mathcal{E}^{test}$\")\n",
    "        # ax.plot(ns_TFZL, means_TFZL[\"b2\"],   \n",
    "        #             \"x--\", label=\"b2\")\n",
    "        ax.plot(ns_TFZL, means_TFZL[\"b1\"],   \n",
    "                    \"d-\", label=\"Bound\")\n",
    "        ax.set_xlabel(\"n\")\n",
    "        # ax.set_ylabel(\"Value\")\n",
    "        if scenario==\"fixed_m\":\n",
    "            ax.set_title(f\"Trained from zero loss network (m={min(n_list)})\")\n",
    "        if scenario==\"m_eq_n\":\n",
    "            ax.set_title(f\"Trained from zero loss network (m=n)\")\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save==True:\n",
    "            os.makedirs(\"plots\", exist_ok=True)\n",
    "            fname = f\"plots/Etest_b1_b2_TFZL_{scenario}.png\"\n",
    "            fig.savefig(fname, dpi=200)\n",
    "\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"No TFZL runs for scenario '{scenario}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single plot of Etest for ZL, TFZL and RI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_compare_Etest(df, n_list, scenario=\"fixed_m\", tol=1e-3, save=False):\n",
    "    \"\"\"\n",
    "    Single plot: Etest vs n for\n",
    "      - ZL\n",
    "      - TFZL\n",
    "      - RI (all runs)\n",
    "      - RI (good seeds: Etrain < tol)\n",
    "\n",
    "    Uses mean ± std across runs for each (exp_type, n).\n",
    "\n",
    "    scenario: 'fixed_m' or 'm_eq_n'\n",
    "    \"\"\"\n",
    "    cols = [\"Etest\"]\n",
    "\n",
    "    # ZL\n",
    "    df_ZL = df[(df[\"scenario\"] == scenario) &\n",
    "               (df[\"exp_type\"] == \"ZL\")]\n",
    "    ns_ZL, means_ZL, stds_ZL = _aggregate_by_n(df_ZL, n_list, cols)\n",
    "\n",
    "    # TFZL\n",
    "    df_TFZL = df[(df[\"scenario\"] == scenario) &\n",
    "                 (df[\"exp_type\"] == \"TFZL\")]\n",
    "    ns_TFZL, means_TFZL, stds_TFZL = _aggregate_by_n(df_TFZL, n_list, cols)\n",
    "\n",
    "    # RI (all runs)\n",
    "    df_RI_all = df[(df[\"scenario\"] == scenario) &\n",
    "                   (df[\"exp_type\"] == \"RI\")]\n",
    "    ns_RI_all, means_RI_all, stds_RI_all = _aggregate_by_n(df_RI_all, n_list, cols)\n",
    "\n",
    "    # RI (good seeds)\n",
    "    df_RI_good = df[(df[\"scenario\"] == scenario) &\n",
    "                    (df[\"exp_type\"] == \"RI\") &\n",
    "                    (df[\"Etrain\"] < tol)]\n",
    "    ns_RI_good, means_RI_good, stds_RI_good = _aggregate_by_n(df_RI_good, n_list, cols)\n",
    "\n",
    "    if not (ns_ZL or ns_TFZL or ns_RI_all or ns_RI_good):\n",
    "        print(f\"No ZL/TFZL/RI data for scenario '{scenario}'.\")\n",
    "        return\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7, 5))\n",
    "\n",
    "    if ns_ZL:\n",
    "        ax.plot(\n",
    "            ns_ZL,\n",
    "            means_ZL[\"Etest\"],\n",
    "            \"o-\",\n",
    "            label=\"ZL\",\n",
    "        )\n",
    "    if ns_TFZL:\n",
    "        ax.plot(\n",
    "            ns_TFZL,\n",
    "            means_TFZL[\"Etest\"],\n",
    "            \"x--\",\n",
    "            label=\"TFZL\",\n",
    "        )\n",
    "        \n",
    "    # if ns_RI_all:\n",
    "    #     ax.errorbar(\n",
    "    #         ns_RI_all,\n",
    "    #         means_RI_all[\"Etest\"],\n",
    "    #         yerr=stds_RI_all[\"Etest\"],\n",
    "    #         fmt=\"d-\",\n",
    "    #         label=\"RI (all)\", capsize=3,\n",
    "    #     )\n",
    "    if ns_RI_good:\n",
    "        ax.errorbar(\n",
    "            ns_RI_good,\n",
    "            means_RI_good[\"Etest\"],\n",
    "            yerr=stds_RI_good[\"Etest\"],\n",
    "            fmt=\"x--\",\n",
    "            label=f\"RI ($\\mathcal{{E}}^{{train}}$ < {tol})\",capsize=3,\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel(\"n\")\n",
    "    ax.set_ylabel(f\"$\\mathcal{{E}}^{{test}}$\")\n",
    "    if scenario==\"fixed_m\":\n",
    "        ax.set_title(f\"Comparison of test error $\\mathcal{{E}}^{{test}}$ (m={min(n_list)})\")\n",
    "    if scenario==\"m_eq_n\":\n",
    "        ax.set_title(f\"Comparison of test error $\\mathcal{{E}}^{{test}}$ (m=n)\")\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save==True:\n",
    "        os.makedirs(\"plots\", exist_ok=True)\n",
    "        fname = f\"plots/compare_Etest_all_{scenario}.png\"\n",
    "        fig.savefig(fname, dpi=200)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produces a single plot for chosen bounds for RI and ZL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_all_bounds(df, n_list, scenario=\"fixed_m\", tol=1e-3, save=False, ZLb0=True):\n",
    "    \"\"\"\n",
    "    Single plot for (b2, b1, b0) for RI and (b2, b1, b0) for ZL vs n.\n",
    "    \n",
    "    - RI uses good seeds only: Etrain < tol.\n",
    "\n",
    "    scenario: 'fixed_m' or 'm_eq_n'\n",
    "    \"\"\"\n",
    "    cols = [\"b1\"]\n",
    "\n",
    "    # RI (good seeds)\n",
    "    df_RI = df[(df[\"scenario\"] == scenario) &\n",
    "               (df[\"exp_type\"] == \"RI\") &\n",
    "               (df[\"Etrain\"] < tol)]\n",
    "    ns_RI, means_RI, stds_RI = _aggregate_by_n(df_RI, n_list, cols)\n",
    "\n",
    "    # ZL\n",
    "    df_ZL = df[(df[\"scenario\"] == scenario) &\n",
    "               (df[\"exp_type\"] == \"ZL\")]\n",
    "    ns_ZL, means_ZL, _ = _aggregate_by_n(df_ZL, n_list, cols)\n",
    "\n",
    "    if not ns_RI and not ns_ZL:\n",
    "        print(f\"No RI/ZL data for scenario '{scenario}'.\")\n",
    "        return\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "    if ns_RI:\n",
    "        # ax.errorbar(ns_RI, means_RI[\"b2\"], yerr=stds_RI[\"b2\"], fmt=\"o-\", label=\"RI b2\", capsize=3)\n",
    "        ax.errorbar(ns_RI, means_RI[\"b1\"], yerr=stds_RI[\"b1\"], fmt=\"s-\", label=\"RI bound\", capsize=3)\n",
    "        # ax.errorbar(ns_RI, means_RI[\"b0\"], yerr=stds_RI[\"b0\"], fmt=\"x--\", label=\"RI b0\", capsize=3)\n",
    "\n",
    "    if ns_ZL:\n",
    "        # ax.plot(ns_ZL, means_ZL[\"b2\"], \"o--\", label=\"ZL b2\")\n",
    "        ax.plot(ns_ZL, means_ZL[\"b1\"], \"s--\", label=\"ZL bound\")\n",
    "        # if ZLb0:\n",
    "        #     ax.plot(ns_ZL, means_ZL[\"b0\"], \"d--\", label=\"ZL b0\")\n",
    "\n",
    "    ax.set_xlabel(\"n\")\n",
    "    ax.set_ylabel(\"Value\")\n",
    "    if scenario==\"fixed_m\":\n",
    "        ax.set_title(f\"All bounds (m={min(n_list)})\")\n",
    "    if scenario==\"m_eq_n\":\n",
    "        ax.set_title(f\"All bounds (m=n)\")\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save==True:\n",
    "        os.makedirs(\"plots\", exist_ok=True)\n",
    "        fname = f\"plots/all_bounds_RI_ZL_{scenario}_ZLb0-{ZLb0}.png\"\n",
    "        fig.savefig(fname, dpi=200)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes in saved data frames for architectures `M` in `M_list` above and plots the chosen column (say, Etest or b1) vs `n_list` for each `M`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_compare_archits(col, M_list, n_list, scenario=\"fixed_m\", tol=1e-3, save=False):\n",
    "    '''\n",
    "    Takes in saved data frames for architectures M in M_list \n",
    "    and plots the chosen column col vs n_list for each M\n",
    "    '''\n",
    "    cols = [col]\n",
    "    fig, ax = plt.subplots(figsize=(7, 4))\n",
    "\n",
    "    # RI (good seeds)\n",
    "    for M in M_list:\n",
    "        df = pd.read_csv(f'./experiments/exp17/df_exp17_{M}.csv')   # Input file\n",
    "        df_RI = df[(df[\"scenario\"] == scenario) &\n",
    "                   (df[\"exp_type\"] == \"RI\") &\n",
    "                   (df[\"Etrain\"] < tol)]\n",
    "        ns_RI, means_RI, stds_RI = _aggregate_by_n(df_RI, n_list, cols)\n",
    "        ax.errorbar(ns_RI, means_RI[col], yerr=stds_RI[col], label=f\"{M}\", capsize=3)\n",
    "\n",
    "    ax.set_xlabel(\"n\")\n",
    "    # ax.set_ylabel(\"Value\")\n",
    "    if scenario==\"fixed_m\":\n",
    "        ax.set_title(f\"Bound for RI ($\\mathcal{{E}}^{{train}}$ < {tol}, m={min(n_list)})\")\n",
    "    if scenario==\"m_eq_n\":\n",
    "        ax.set_title(f\"Bound for different depths (m=n)\")\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save==True:\n",
    "        os.makedirs(\"plots\", exist_ok=True)\n",
    "        fname = f\"plots/bound_RI_different_depths_{scenario}.png\"\n",
    "        fig.savefig(fname, dpi=200)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Running experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment parameters "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "4mLs3Al2909B"
   },
   "source": [
    "Parameters (necessarily need to be defined in *Experimental setup* below):\n",
    "* `M` = list, architecture of network. Enter all numbers from M0 to Q (inclusive) as a list\n",
    "* `bias` = boolean, `default=False`\n",
    "* `n_list` = list of int, training set sizes to be considered\n",
    "* `train_seed` seed for generating training set, `default=30`\n",
    "* `test_seed` seed for generating test set, `default=10`\n",
    "* `scenarios` = list, possible elements are \"fixed_m\" (m = min(n_list)) and \"m_eq_n\" (m=n)\n",
    "* `TFZL` = boolean, if considering TFZL in this experiment\n",
    "* `random_init` = boolean, if considering RI in this experiment\n",
    "* `num_RI_runs`= int, how many random initializations for RI\n",
    "* `epochs` = int, used 70 in paper\n",
    "* `tol` = float, training error tolerance for randomly initialized networks\n",
    "* `M_list` = list of `M`s, for comparing architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment setup\n",
    "\n",
    "# For training\n",
    "M = [784, 784, 10]        # architecture \n",
    "bias = False\n",
    "n_list = [20, 30]        # [20, 60, 100, 200, 300, 400, 475, 500, 525, 550]  used for manuscript plots \n",
    "train_seed = 30\n",
    "TFZL = True\n",
    "random_init = True\n",
    "num_RI_runs = 1          # number of runs for random init network, between 2 and 10 for published experiments\n",
    "epochs = 10              # 70 in paper\n",
    "\n",
    "# For computing quantities of interest\n",
    "test_seed=10\n",
    "scenarios=[\"fixed_m\"]\n",
    "tol = 1e-3                # Etrain < tol, for randomly initialized trained net\n",
    "\n",
    "# For comparing architectures \n",
    "# M_list = ['[784, 600, 10]', '[784, 600, 100, 10]', '[784, 600, 300, 100, 10]', '[784, 600, 300, 200, 100, 10]', '[784, 600, 300, 200, 100, 50, 10]']\n",
    "M_list = ['[784, 784, 10]', '[784, 784, 784, 10]', '[784, 784, 784, 784, 10]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If running new experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Train networks (saves model parameters if `save_models=True`), run all experiments and save  to data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = train_and_run_all_experiments(\n",
    "    n_list=n_list,\n",
    "    M=M,\n",
    "    scenarios=scenarios,\n",
    "    train_seed=train_seed, test_seed=test_seed,\n",
    "    random_init=random_init, TFZL=TFZL,\n",
    "    num_RI_runs=num_RI_runs,\n",
    "    epochs=epochs, \n",
    "    tol=tol, \n",
    "    save_models=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train networks and save models as .pt files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_nets(n_list, M, train_seed=train_seed, \n",
    "#                TFZL=False, \n",
    "#                random_init=random_init, num_RI_runs=num_RI_runs,\n",
    "#                epochs = epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for saved model parameters (.pt), compute quantities of interest and save to data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = networks_to_df(n_list, M, bias, num_RI_runs, TFZL, random_init, train_seed, test_seed, epochs, scenarios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save df to a spreadsheet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(f'df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If loading previously run experiment data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "If reading a previously generated data frame, load it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating existing saved data frame (df2) with newly generated one (df1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = pd.read_csv('other-file.csv')\n",
    "# new_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# df = new_df.loc[new_df.astype(str).drop_duplicates().index]\n",
    "\n",
    "## Save new df to csv\n",
    "# df.to_csv('new-df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save=False # If plots will be saved to .png\n",
    "\n",
    "for scenario in scenarios:\n",
    "# Etest + bound(s) plots for RI, ZL, TFZL:\n",
    "    plot_Etest_and_bounds(df, n_list, tol=tol, scenario=scenario, save=save)\n",
    "\n",
    "# Compare Etest for RI, ZL and TFZL:\n",
    "    plot_compare_Etest(df, n_list, tol=tol, scenario=scenario, save=save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function takes as input data frames saved as `./experiments/exp17/df_exp17_{M}.csv` for architectures `M` in `M_list` above and plots the chosen column (say, Etest or b1) vs $n \\in$ `n_list` for each `M`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False\n",
    "# plot_compare_archits('b1', M_list, n_list, scenario=scenario, tol=tol, save=save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLy9SdnF_Qvz"
   },
   "source": [
    "___\n",
    "## Other computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for seed in [30, 40]:\n",
    "#     print(f\"Training seed {seed}\")\n",
    "#     for n in n_list:\n",
    "#         X, _, _ = train_imports(n, seed)\n",
    "#         print(f\"Rank for n={n} = {torch.linalg.matrix_rank(X)}; ratio = {torch.linalg.matrix_rank(X)/n:.2f}\")\n",
    "#     print()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
